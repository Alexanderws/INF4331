{\rtf1\ansi\ansicpg1252\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgenericrgb\c0\c0\c0;\csgenericrgb\c100000\c100000\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 I ran both the normal, Python method and the one using Numpy a few times. Below are data gathered from both methods with n=100 and n=100000\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\fs22 \cf2 \cb3 \CocoaLigature0 [Python implementation, default method, n=100] finished in 0.059 ms\
[Numpy implementation, default method, n=100] finished in 0.188 ms\
[Python implementation, default method, n=100000] finished in 53.911 ms\
[Numpy implementation, default method, n=100000] finished in 1.497 ms\
\
This shows that the time for the normal Python method is fairly linear to n. It also shows that the Numpy implementation uses much less time, though only after n  is sufficiently high, as normal Python is fastest for n values below 200 or there abouts. The time saved is exponentially increased as n increases.}